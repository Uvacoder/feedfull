{
  "title": "A Facebook bug led to increased views of harmful content over six months",
  "url": "https://www.theverge.com/2022/3/31/23004326/facebook-news-feed-downranking-integrity-bug",
  "date": "2022-03-31T18:32:49.000Z",
  "author": "Alex Heath",
  "content": "      <figure>      <img alt=\"\" src=\"https://cdn.vox-cdn.com/thumbor/24FOPZylLQtfeoaSMsVQnRuaRQw=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/70695106/acastro_180828_1777_facebook_0001.0.jpg\" />        <figcaption>Illustration by Alex Castro / The Verge</figcaption>    </figure>  <p>The social network touts downranking as a way to thwart problematic content, but what happens when that system breaks?</p> <p class=\"p--has-dropcap\" id=\"NDrnHw\">A group of Facebook engineers identified a “massive ranking failure” that exposed as much as half of all News Feed views to “integrity risks” over the past six months, according to an internal report on the incident obtained by <em>The Verge</em>.</p><p id=\"yQsjpi\">The engineers first noticed the issue last October, when a sudden surge of misinformation began flowing through the News Feed, notes the report, which was shared inside the company last week. Instead of suppressing dubious posts reviewed by the company’s network of outside fact-checkers, the News Feed was instead giving the posts distribution, spiking views by as much as 30 percent globally. Unable to find the root cause, the engineers watched the surge subside a few weeks later and then flare up repeatedly until the ranking issue was fixed on March 11th.</p><p id=\"j4Q4N5\">In addition to posts flagged by fact-checkers, the internal investigation found that, during the bug period, Facebook’s systems failed to properly demote nudity, violence, and even Russian state media the social network <a href=\"https://www.theverge.com/2022/3/1/22956532/facebook-russian-state-media-global-recommendation-suspension\">recently pledged to stop recommending</a> in response to the country’s invasion of Ukraine. The issue was internally designated a level-one SEV, or Severe Engineering Vulnerability — a label reserved for the company’s worst technical crises, like Russia’s <a href=\"https://www.theverge.com/2022/3/4/22960739/russia-internet-block-facebook-meta-roskomnadzor-ukraine\">ongoing block of Facebook and Instagram</a>.</p><div class=\"c-float-right\"><aside id=\"ET2OaC\"><q>The technical issue was first introduced in 2019 but didn’t create a noticeable impact until October 2021</q></aside></div><p id=\"ZdSmNp\">Meta spokesperson Joe Osborne confirmed the incident in a statement to <em>The Verge</em>, saying the company “detected inconsistencies in downranking on five separate occasions, which correlated with small, temporary increases to internal metrics.” The internal documents said the technical issue was first introduced in 2019 but didn’t create a noticeable impact until October 2021. “We traced the root cause to a software bug and applied needed fixes,” said Osborne, adding that the bug “has not had any meaningful, long-term impact on our metrics.”</p><p id=\"L5rQQj\">For years, Facebook has touted downranking as a way to improve the quality of the News Feed and has steadily expanded the kinds of content that its automated system acts on. Downranking has been used in response to wars and <a href=\"https://www.theverge.com/2020/10/15/21516729/facebook-twitter-new-york-post-hunter-biden-emails-laptop-story-social-media-moderation-problems\">controversial political stories</a>, sparking concerns of <a href=\"https://www.theverge.com/2021/6/8/22524332/instagram-how-it-works-blog-post-adam-mosseri-shadowban\">shadow banning</a> and <a href=\"https://www.theverge.com/2020/6/24/21302170/facebook-google-brian-schatz-john-thune-section-230-content-moderation\">calls for legislation</a>. Despite its increasing importance, Facebook has yet to open up about its impact on what people see and, as this incident shows, what happens when the system goes awry.</p><p id=\"4pvmtL\">In 2018, CEO Mark Zuckerberg explained that downranking fights the impulse people have to inherently engage with “more sensationalist and provocative” content. “Our research suggests that no matter where we draw the lines for what is allowed, as a piece of content gets close to that line, people will engage with it more on average — even when they tell us afterwards they don’t like the content,” he <a href=\"https://www.facebook.com/notes/751449002072082/\">wrote in a Facebook post</a> at the time.</p><div class=\"c-float-right\"><aside id=\"YFRk24\"><q>“We need real transparency to build a sustainable system of accountability”</q></aside></div><p id=\"NYSUPA\">Downranking not only suppresses what Facebook calls <a href=\"https://transparency.fb.com/features/approach-to-ranking/content-distribution-guidelines/content-borderline-to-the-community-standards\">“borderline” content</a> that comes close to violating its rules but also content its AI systems suspect as violating but needs further human review. The company <a href=\"https://www.theverge.com/2021/9/23/22688840/facebook-releases-content-distribution-guidelines-for-news-feed\">published a high-level list of what it demotes</a> last September but hasn’t peeled back how exactly demotion impacts distribution of affected content. Officials have told me they hope to shed more light on how demotions work but have concern that doing so would help adversaries game the system.</p><p id=\"O2xuJY\">In the meantime, Facebook’s leaders regularly brag about how their AI systems are <a href=\"https://about.fb.com/news/2021/02/update-on-our-progress-on-ai-and-hate-speech-detection/\">getting better each year</a> at proactively detecting content like hate speech, placing greater importance on the technology as a way to moderate at scale. Last year, Facebook said it <a href=\"https://www.theverge.com/2021/8/31/22650309/facebook-expands-political-content-reduction-tests-costa-rica-spain-sweden-ireland\">would start downranking all political content</a> in the News Feed — part of CEO Mark Zuckerberg’s push to return the Facebook app <a href=\"https://www.theverge.com/2022/2/15/22935080/facebook-meta-news-feed-renaming-branding-political-content-misinformation\">back to its more lighthearted roots</a>.</p><p id=\"UlHHZk\">I’ve seen no indication that there was malicious intent behind this recent ranking bug that impacted up to half of News Feed views over a period of months, and thankfully, it didn’t break Facebook’s other moderation tools. But the incident shows why more transparency is needed in internet platforms and the algorithms they use, according to Sahar Massachi, a former member of Facebook’s Civic Integrity team.</p><p id=\"Xa2v1K\">“In a large complex system like this, bugs are inevitable and understandable,” Massachi, who is now co-founder of the nonprofit <a href=\"https://integrityinstitute.org/\">Integrity Institute</a>, told <em>The Verge</em>. “But what happens when a powerful social platform has one of these accidental faults? How would we even know? We need real transparency to build a sustainable system of accountability, so we can help them catch these problems quickly.”</p>",
  "image": "https://cdn.vox-cdn.com/thumbor/O3t-YbUpkAz9E1kFH_L2s4mUUUY=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/12742467/acastro_180828_1777_facebook_0001.jpg",
  "description": "What happens when the News Feed breaks?",
  "publisher": "The Verge",
  "publisherUrl": "https://www.theverge.com/"
}