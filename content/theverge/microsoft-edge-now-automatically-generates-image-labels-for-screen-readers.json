{
  "title": "Microsoft Edge now automatically generates image labels for screen readers",
  "url": "https://www.theverge.com/2022/3/18/22984474/microsoft-edge-automatic-image-labels-accessibility-feature",
  "date": "2022-03-18T10:47:46.000Z",
  "author": "Tom Warren",
  "content": "      <figure>      <img alt=\"\" src=\"https://cdn.vox-cdn.com/thumbor/7yVi7t0EZgHZGkfvnNy2MReWlUo=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/70639871/acastro_200207_3900_Edge_0001.0.0.jpg\" />        <figcaption>Illustration by Alex Castro / The Verge</figcaption>    </figure>  <p id=\"76kv8J\">More than half of the images on the web are missing alt text, according to Microsoft. Image labels (alternative text) are key for many who are blind or low vision, as they provide screen readers with text to read aloud. Microsoft is now attempting to fill the gap with auto-generated alt text for images on the web.</p><p id=\"AAtmwL\">Existing screen readers currently read out “unlabeled graphic” if there’s no description of an image at all which isn’t very helpful. Microsoft Edge has now been updated to improve the screen reader experience for all of the images on the web without alt text.</p><p id=\"us0Z4F\">“When a screen reader finds an image without a label, that image can be automatically processed by machine learning (ML) algorithms to describe the image in words and capture any text it contains,” <a href=\"https://blogs.windows.com/msedgedev/2022/03/17/appears-to-say-microsoft-edge-auto-generated-image-labels/\">explains Travis Leithead</a>, a program manager on Microsoft’s Edge platform team. “The algorithms are not perfect, and the quality of the descriptions will vary, but for users of screen readers, having some description for an image is often better than no context at all.”</p>  <figure class=\"e-image\">        <img alt=\" \" data-mask-text=\"false\" src=\"https://cdn.vox-cdn.com/thumbor/o4F_9h9CZhzZQ3AAkghqUlhn9HU=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/23326492/oUdX90O.png\">      <cite>Image: Microsoft</cite>      <figcaption><em>The new image descriptions feature.</em></figcaption>  </figure><p id=\"zrbPnd\">Microsoft Edge can now send unlabeled images to its Azure computer vision API for processing, which is governed by Microsoft’s <a href=\"https://docs.microsoft.com/en-us/microsoft-edge/privacy-whitepaper/#image-descriptions\">privacy promises</a>. The vision API creates alt text in English, Spanish, Japanese, Portuguese, or Chinese Simplified which can then be deciphered by screen readers. Microsoft Edge won’t attempt to add automatic labels to images that are smaller than 50 x 50 pixels, very large image files, images that are marked as decorative, or images that the Vision API categorizes as pornographic, gory, or sexually suggestive.</p><p id=\"vpcvR4\">Microsoft is rolling out this new feature immediately in Microsoft Edge for Windows, Mac, and Linux, but it won’t be available in Edge on Android or iOS yet. You can try the new feature out by enabling “Get image descriptions from Microsoft for screen readers” in edge://settings/accessibility, and using Narrator or another screen reader to browse the web.</p><p id=\"vEmreu\">“This feature is still new, and we know that we are not done,” says Leithead. “We’ve already found some ways to make this feature even better, such as when images <em>do </em>have a label, but that label is not very helpful. Continuous image recognition and algorithm improvements will also refine the quality of the service.”</p>",
  "image": "https://cdn.vox-cdn.com/thumbor/h2TNhqf8u7_lV8mmNRHNxi4G-H0=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/19713463/acastro_200207_3900_Edge_0001.0.jpg",
  "description": "A great new web accessibility feature.",
  "publisher": "The Verge",
  "publisherUrl": "https://www.theverge.com/"
}